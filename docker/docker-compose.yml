name: text2vec-weaviate
services:
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.25.1
    ports:
      - "8080:8080"
      - "50051:50051"
    volumes:
      - ./.data:/var/lib/weaviate
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      ENABLE_MODULES: 'text2vec-transformers'
      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'
      CLUSTER_HOSTNAME: 'node1'

  t2v-transformers:
    build:
      context: ./
      dockerfile: t2v-transformers.Dockerfile
    runtime: nvidia
    environment:
      ENABLE_CUDA: 1
    ports:
      - "8081:8080"  # expose if you want to hit the inference container directly
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    secrets:
      - hf_hub_token

# Root-level secrets definition
secrets:
  hf_hub_token:
    file: ./secrets/hf_hub_token
