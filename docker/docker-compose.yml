name: kri-local-rag
services:
  # ---------- Local Weaviate database ------------------------------------------------
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.32.0
    ports:
      - "127.0.0.1:8080:8080"
      - "127.0.0.1:50051:50051"
    volumes:
      - weaviate_db:/var/lib/weaviate
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      DEFAULT_VECTORIZER_MODULE: 'none' # We are providing vectors manually
      # ENABLE_MODULES: 'text2vec-huggingface,reranker-huggingface' # Still needed for reranker
      CLUSTER_HOSTNAME: 'node1'
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:8080/v1/.well-known/ready || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 30s

  # ---------- Local LLM server for generating RAG answers ---------------------------------------------------
  ollama:
    image: ${OLLAMA_IMAGE:-ollama/ollama:latest}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ../model_cache:/root/.ollama
    ports:
      - "127.0.0.1:11434:11434"
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s

  # ---------- RAG App Container (supports both web app and CLI) -----------------------------------------
  app:
    profiles: ["prod"]
    image: kri-local-rag-app
    build:
      context: ..
      dockerfile: docker/app.Dockerfile
      target: runtime

    ports:
      - "8501:8501"
    volumes:
      - ../backend:/app/backend # Live backend code
      - ../frontend:/app/frontend # Live frontend code
      - ../data:/app/data # Live data access
      - ../example_data:/app/example_data:ro # Ensure example_data matches project layout
      - ../logs:/app/logs # Live log access
      - ../tests:/app/tests # Mount tests for in-container testing
    working_dir: /app
    # Auto-start Streamlit when container starts (headless + no telemetry)
    command: ["streamlit", "run", "frontend/rag_app.py", "--server.port=8501", "--server.address=0.0.0.0", "--server.headless=true", "--browser.gatherUsageStats=false"]
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:8501/_stcore/health || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 30s
    depends_on:
      weaviate:
        condition: service_healthy
      ollama:
        condition: service_healthy
    environment:
      # Point the Python code to the other services inside the compose network
      - OLLAMA_URL=http://ollama:11434
      - WEAVIATE_URL=http://weaviate:8080
      - STREAMLIT_SERVER_HEADLESS=true
      - STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
      - APP_LOG_DIR=/app/logs

  # ---------- Test App Container (profile: test) -----------------------------------------
  app-test:
    profiles: ["test"]
    extends: app
    image: kri-local-rag-app:test
    build:
      target: runtime
      args:
        INSTALL_DEV: "1"
    ports: []
    command: ["tail", "-f", "/dev/null"]
    healthcheck:
      test: ["CMD-SHELL", "exit 0"]

  # ---------- One-off Ingestion Utility -----------------------------------------
  ingester:
    profiles: ["ingest"]
    image: kri-local-rag-app # reuse the APP image
    depends_on:
      weaviate:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      - ../backend:/app/backend # Live backend code
      - ../data:/app/data # Live data access
      - ../logs:/app/logs # Live log access
    environment:
      # Point the Python code to the other services inside the compose network
      - OLLAMA_URL=http://ollama:11434
      - WEAVIATE_URL=http://weaviate:8080
      - APP_LOG_DIR=/app/logs
    command: ["python", "-m", "backend.ingest", "--data-dir", "/app/data"]

volumes:
  weaviate_db:
