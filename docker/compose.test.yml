services:
  weaviate:
    ports: [] # Un-expose ports for tests

  # Shared Ollama service with isolation
  ollama:
    ports: [] # Un-expose ports for tests
    # Add resource limits for test environment
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  app:
    build:
      context: ..
      dockerfile: docker/app.test.Dockerfile
    image: kri-local-rag-app-test
    ports: [] # Un-expose ports for tests
    volumes:
      - ../backend:/app/backend # Live backend code
      - ../frontend:/app/frontend # Live frontend code
      - ../tests:/app/tests # Live tests for dynamic development
      - ../data:/app/data # Live data access
      - ../example_data:/app/example_data:ro # Ensure example_data matches project layout
      - ../logs:/app/logs # Live log access
    # Keep container alive for exec commands without starting the web server
    command: ["tail", "-f", "/dev/null"]
    healthcheck:
      # The default healthcheck probes a web server that isn't running with the test command.
      # This simple check just ensures the container is running.
      test: ["CMD-SHELL", "exit 0"]
    environment:
      # Point the Python code to the shared Ollama service
      - OLLAMA_URL=http://ollama:11434
      - WEAVIATE_URL=http://weaviate:8080
    depends_on:
      weaviate:
        condition: service_healthy
      ollama:
        condition: service_healthy
